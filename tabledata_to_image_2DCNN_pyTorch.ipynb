{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tabledata_to_image_2DCNN_pyTorch.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPeZS308GY7lZazgrmXUWHG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"ir0L7XWyM3g3","executionInfo":{"status":"ok","timestamp":1637191424244,"user_tz":300,"elapsed":27633,"user":{"displayName":"Rageeni Sah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12141982895851443668"}}},"source":["## limport required Pytorch methods\n","from torch.utils.data import Dataset\n","from torchvision import transforms"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"ukOlors-IDbg","executionInfo":{"status":"ok","timestamp":1637191424253,"user_tz":300,"elapsed":25,"user":{"displayName":"Rageeni Sah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12141982895851443668"}}},"source":["# Custom Class to load data from local system to Pytorch model\n","class LoadTerrainDataSet(Dataset):\n","  def __init__(self, path, transform): \n","    self.path = path\n","    self.sample = []\n","    self.label = []\n","    self.transform = transform\n","    # read data from sources\n","    train_data = pd.read_csv(self.path+'trainData.csv', header = None) # replace data path and format\n","    noOfCols = train_data.shape[1]\n","    noOfRows = train_data.shape[0]\n","    train_X = train_data.loc[:,1:] # assuming 2nd column onwards represents features of the dataset\n","    train_y = train_data.loc[:,0] # assuming 1st column represents target variable in the training dataset \n","\n","    # It is important to understand dimension of the image to modify rest of the code. Below code is written\n","    # to read 2D data of size 48 X N size as an image with a window of size 48 pixels. \n","    # For example: 0th index to 47th index is height of the first image;\n","    # 1st index to 48th index is the height of another 2nd image and so on.\n","    # Feel free to modify the code as per requirement size.\n","    # Each image is stored as 2D numpy array in the list (sample).\n","    # Label is stored as 1D numpy array in the list (label).\n","    start_index = 1\n","    end_index = 48\n","    image_height = 48\n","    for indx in range(1,noOfRows - image_height):\n","      start_index = indx\n","      self.sample.append(train_X[start_index:end_index+1].values)\n","      self.label.append(train_y[end_index]) \n","      end_index += 1\n","\n","  def __len__(self):\n","    return len(self.sample)\n","\n","  def __getitem__(self, index):\n","    # This method is called to feed a row information to the model for training.\n","    # Each of the image is transformed to 3 dimension torch (C,H,W). \n","    # (C,H,W) represents channel, rows and columns of the image.\n","    # When C = 1, image is passed as gray scaled image. When C = 3, image is considered to be RGB image.\n","    # Note: in __init__ method, the numpy arrays should be created accordingly to be considered \n","    # as gray-scaled or RGB images before changing C agrument.\n","    X,y = self.sample[index], self.label[index]\n","    r,c = X.shape\n","    X = self.transform(torch.from_numpy(X.reshape((1,r,c))))\n","    y = torch.from_numpy(np.asarray(y))\n","    return X,y"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"P_sDAxC9Lb_M","executionInfo":{"status":"ok","timestamp":1637191433547,"user_tz":300,"elapsed":174,"user":{"displayName":"Rageeni Sah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12141982895851443668"}}},"source":["## Code after defining class\n","# Convert data to a normalized torch.FloatTensor\n","transform = transforms.Compose([\n","    transforms.Normalize((0.5), (0.5))\n","    ])\n","\n","# Creates 2-Dimentional data as an image \n","# data = LoadTerrainDataSet(toPath, transform)\n","\n","## data can be used as datas source in DataLoader.\n","## Example code\n","# Split total data into training and validation datasets\n","# train_set, validation_set = torch.utils.data.random_split(data, [train_set_len, valid_set_len])\n","\n","# train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n","# validation_loader = DataLoader(validation_set, batch_size=batch_size, shuffle=True)"],"execution_count":3,"outputs":[]}]}